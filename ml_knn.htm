<html>
<head>
	<title>線上教材：音樂資訊分析</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<link rel=stylesheet type="text/css" href="myCss.css">
	<base target="_blank">
	<script type="text/javascript" src="shCore.js"></script>
	<script type="text/javascript" src="shBrushPython.js"></script>
	<link href="shCore.css" rel="stylesheet" type="text/css" />
	<link href="shThemeDefault.css" rel="stylesheet" type="text/css" />
	<script type="text/javascript">
		SyntaxHighlighter.all();
	</script>
</head>

<body bgcolor="#ccccff">

<blockquote>

<p>
最近鄰居分類(k-nearest neighbors, k-NN)的概念相當簡單：一個資料點在空間中跟那些類別的點最接近，就說它是屬於哪一個類別。這個方法不需要訓練過程，或者說訓練就是把所有資料記起來；而在預測的階段，則是將待測點與其他資料點計算距離，找出最接近的 k 的點，並依據這 k 的點所屬的類別或值進行投票，來做為待測點的預測結果。
</p>

<p>我們使用 scikit-learn 的 neighbors.KNeighborsClassifier 來幫我們執行 k-NN 演算法，使用的資料集是 <a href="https://archive.ics.uci.edu/ml/datasets/wine">Wine Data Set</a>，該資料集在 scikit-learn 有內建一版，你可以直接透過 import 相關函式來使用，不必自己下載：</p>
<pre class="brush: py">
import numpy as np
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

dataset = load_wine()
print('Data shapes:', dataset.data.shape, dataset.target.shape)

X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target)
print('Training data shapes:', X_train.shape, y_train.shape)
print('Test data shapes:', X_test.shape, y_test.shape)

model = KNeighborsClassifier(n_neighbors=1)
model.fit(X_train, y_train)
pred = model.predict(X_test)
print('Accuracy: {:.2f}%'.format(100*np.mean(pred==y_test)))
</pre>

<p>下面對 KNeighborsClassifier 的部分參數進行一些說明，若需要更多細節，可以參考官方文件。</p>
<ul>
	<li>n_neighbors: 一次要選幾個鄰居。上述範例使用一個鄰居，你也可以試試看多一點的效果。一般來說，鄰居數目會選用與類別數目不相等的奇數，以盡可能避開票數相同的狀況。</li>
	<li>weights: 距離的權重，或是說投票的方式。預設是相等權重，也提供了愈遠愈輕，你也可以撰寫一個函式來自行定義。</li>
	<li>algorithm: 找最鄰居的演算法，除了最簡單的暴力法以外，也提供了一些 tree-based 的近似方法。預設會幫你自動選擇。</li>
</ul>

</blockquote>

</body></html>
